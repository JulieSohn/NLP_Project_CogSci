import requests
from bs4 import BeautifulSoup as bs
import json
import math
import pandas as pd
import csv
def getInfo(url):
res=requests.get(url) # this is equal to the html of the website
soup = bs(res.content, 'lxml')
data = json.loads(soup.select_one('[type='application/ld+json']').text.strip()[:-1])[0]
return data
#==========================================================================
import numpy as np
import pandas as pd
import csv
import matplotlib.pyplot as plt
import re, string
data =  pd.read_csv("raw_reviews.csv")
pos_len = []
for i, x in zip(data.Review, data.Ranking):
if x == 5:
pos_len.append(len(i))
neg_len = []
for i, x in zip(data.Review, data.Ranking):
if x == 1:
neg_len.append(len(i))
pos_len
print("Avg. length of positive reviews: ", np.mean(pos_len))           # 238.65
print("Avg. length of negative reviews: ", np.mean(neg_len))           # 640.22
print("Standard deviation of positive reviews: ", np.std(pos_len))     # 217.80
print("Standard deviation of negative reviews: ", np.std(neg_len))     # 518.25
data.shape # 3596
data[data.Ranking == 5].shape # 1488
data[data.Ranking == 4].shape # 383
data[data.Ranking == 3].shape # 228
data[data.Ranking == 2].shape # 351
data[data.Ranking == 1].shape # 1146
#==========================================================================
# TIME TRENDS
#==========================================================================
data['ReviewDate'] = data['ReviewDate'].str.extract('(....-..-..)', expand=True)
#make a new column only containing month + one with year
data['year'] = data['ReviewDate'].str.extract('(....)', expand=True)
data['yearmonth'] = data['ReviewDate'].str.extract('(....-..)', expand=True)
data['month'] = data['ReviewDate'].str.extract('(-..-)', expand=True)
data['month'] = [re.sub(r'[\-\'\"\!\?\:\;\_\=\(\)\|\*\@\#\&\$\"\/\%\+\!]+','', x) for x in data['month']]
total_reviews = data.groupby(['Ranking'])['Unnamed: 0'].count().reset_index()
total_reviews.plot(x="Ranking",y="Unnamed: 0",kind="bar",title="Total no. of reviews")
plt.show()
# TWO: create a figure and axis
fig, ax = plt.subplots()
# count the occurrence of each class
dt = data['Ranking'].value_counts()
# get x and y data
points = dt.index
frequency = dt.values
# create bar chart
ax.bar(points, frequency, color = '#5E8CCC')
# set title and labels
ax.set_title('TrustPilot Review Scores')
ax.set_xlabel('Ranking')
ax.set_ylabel('Frequency')
#==========================================================================
# Plotting frequency of reviews: year, month, year-month
#==========================================================================
# Total no. of reviews are increasing. Maybe because TrustPilot has become more popular.
yearly=data.groupby(['year'])['Unnamed: 0'].count().reset_index()
yearly.plot(x="year",y="Unnamed: 0",kind="bar",title="No. of reviews over year", color = '#5E8CCC')
plt.show()
from nltk import sent_tokenize, word_tokenize, sent_tokenize, pos_tag
from nltk.corpus import stopwords
import numpy as np
import re, string
import pandas as pd
import stanfordnlp #not working
py_install("stanfordnlp")
import stanfordnlp #not working
data = pd.read_csv('raw_reviews.csv')
data.shape # 3596, 5
data['ReviewDate'] = data['ReviewDate'].str.extract('(....-..-..)', expand=True)
# Extract the year from column 'ReviewDate'
data['year'] = data['ReviewDate'].str.extract('(....)', expand=True)
# RE removing numbers, as we can't use the information for neither topic detection nor sentiment analysis.
data['clean_text']= [re.sub(r'\d+','', x) for x in data['Review']]
# RE removing some punctuation
data['clean_text'] = [re.sub(r'[\,\-\'\"\:\;\_\=\(\)\|\*\@\#\&\$\"\/\%\+]+','', x) for x in data['clean_text']]
# RE removing non-ASCII characters. Keeps all ASCII and æ, ø and å
data['clean_text'] = [re.sub(r'[^\x00-\x7Fæøå]+','', x) for x in data['clean_text']]
#==========================================================================
# Tokenizing & lemmatizing
#==========================================================================
# Exclude one row because it was empty after cleaning it (raw review only contained numbers)
data = data[data['clean_text'] != '']
# Lemmatize and POS-tag with StanfordNLP
stanford_nlp = stanfordnlp.Pipeline(processors='tokenize,pos,lemma', lang="da")
data['lemmatized'] = [stanford_nlp(i) for i in data['clean_text']]
data['lemmatized'] = [" ".join([(word.lemma) for sentence in i.sentences for word in sentence.words]) for i in data['lemmatized']]
data
data['lemmatized'] = [" ".join([(word.lemma) for sentence in i.sentences for word in sentence.words]) for i in data['lemmatized']]
data['lemmatized']]
data
data['sent_toke'] = [i.replace(' men ', ' . ') for i in data['lemmatized']]
# Split by punctuation
data['sent_toke'] = [sent_tokenize(text.lower(), language = "danish") for text in data['sent_toke']]
data['sent_toke']
# Create a row for each list element
s = data.apply(lambda x: pd.Series(x['sent_toke']),axis=1).stack().reset_index(level=1, drop=True)
s.name = 'sent_toke'
df = data.drop('sent_toke', axis=1).join(s)
data = df #pd.read_csv('preprocessed_reviews.csv')
import nltk
from nltk import FreqDist
import matplotlib.pyplot as plt
import seaborn as sns
def freq_words(x, terms = 30):
all_words = ' '.join([text for text in x])
all_words = all_words.split()
fdist = FreqDist(all_words)
words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})
# selecting top 20 most frequent words
d = words_df.nlargest(columns="count", n = terms)
plt.figure(figsize=(20,5))
ax = sns.barplot(data=d, x= "word", y = "count")
ax.set(ylabel = 'Count')
plt.show()
def freq_words(x, terms = 30):
all_words = ' '.join([text for text in x])
all_words = all_words.split()
fdist = FreqDist(all_words)
words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})
# selecting top 20 most frequent words
d = words_df.nlargest(columns="count", n = terms)
plt.figure(figsize=(20,5))
ax = sns.barplot(data=d, x= "word", y = "count")
ax.set(ylabel = 'Count')
plt.show()
freq_words(data['sent_toke'])
def freq_words(x, terms = 30):
all_words = ' '.join([text for text in x])
all_words = all_words.split()
fdist = FreqDist(all_words)
words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})
# selecting top 20 most frequent words
d = words_df.nlargest(columns="count", n = terms)
plt.figure(figsize=(20,5))
ax = sns.barplot(data=d, x= "word", y = "count")
ax.set(ylabel = 'Count')
plt.show()
# Most common words in dataset
freq_words(data['sent_toke'])
import csv
import pandas as pd
data = data.drop(columns = "Unnamed: 0.1")
data =  pd.read_csv("preprocessed_reviews.csv")
data =  pd.read_csv("preprocessed_reviews.csv")
data = data.drop(columns = "Unnamed: 0.1")
data
data =  pd.read_csv("preprocessed_reviews.csv")
data
data = data.drop(columns = "Unnamed: 0.1")
data
class topic_classification:
# Set topics
def __init__(self):
self.topic_payment = ["udbetaling", "betale", "betaling", "bankoverførsel", "betalingsmulighed",
"betalingsformer", "pris", "penge", "krone", "billigt", "dyr", "tilbud",
"overføre", "overførsel", "dankort", "paypal"]
self.topic_delivery =["postnord", "post nord", "levering", "leveringsdygtig", "modtage",
"leveringstid", "leveringsstid", "ventetid", "behandlingstid", "forsendelse",
"track", "trace", "fringe"] # fringe = fragt
self.topic_return =  ["retur", "returnering", "reklamation", "returret", "refundere", "betale tilbage", "bytte"]
self.topic_products = ["udvalg", "kvalitet", "tøj", "produkt", "vare", "mærke", "sko", "jakke", "taske"]
self.topic_service = ["kundeservice", "service", "support", "spørge", "svare", "telefon", "telefonkø",
"telefonsupport", "chat", "kontakt", "betjening", "mail", "tale", "ring", "behandling",
"medarbejder", "telefonmedarbejde", "kundeservicemedarbejde", "kunde", "kommunikere",
"kommunikation", "dialog"]
self.topic_brand =   ["netbutik", "zalando", "virksomhed", "firma", "webshop", "hjemmeside", "onlin", "app",
"oplevelse", "behandling", "anbefale", "anbefaling", "forretning"]
# Functions
def payment(self, review):
value = 0
for word in self.topic_payment:
value += review.count(word)
if value > 0: return 1
else: return 0
def delivery(self, review):
value = 0
for word in self.topic_delivery:
value += review.count(word)
if value > 0: return 1
else: return 0
def returns(self, review):
value = 0
for word in self.topic_return:
value += review.count(word)
if value > 0: return 1
else: return 0
def products(self, review):
value = 0
for word in self.topic_products:
value += review.count(word)
if value > 0: return 1
else: return 0
def service(self, review):
value = 0
for word in self.topic_service:
value += review.count(word)
if value > 0: return 1
else: return 0
def brand(self, review):
value = 0
for word in self.topic_brand:
value += review.count(word)
if value > 0: return 1
else: return 0
find_topic = topic_classification()
data['money_related'] = [find_topic.payment(i) for i in data['sent_toke']]
data['delivery_service'] = [find_topic.delivery(i) for i in data['sent_toke']]
data['return_service'] = [find_topic.returns(i) for i in data['sent_toke']]
find_topic
data['delivery_service'] = [find_topic.delivery(i) for i in data['sent_toke']]
data['customer_service'] = [find_topic.service(i) for i in data['sent_toke']]
data['brand'] = [find_topic.brand(i) for i in data['sent_toke']]
topic_classification
payment
